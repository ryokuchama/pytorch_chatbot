{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.6"
    },
    "colab": {
      "name": "pytorch_2ch_chatbot.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ryokuchama/pytorch_chatbot_training/blob/master/pytorch_2ch_chatbot.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VGSqJ-i_6KM3",
        "colab_type": "code",
        "outputId": "1efaa7f1-a851-4d60-cae6-54fb3edbd0f3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "!pip install sentencepiece"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting sentencepiece\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/74/f4/2d5214cbf13d06e7cb2c20d84115ca25b53ea76fa1f0ade0e3c9749de214/sentencepiece-0.1.85-cp36-cp36m-manylinux1_x86_64.whl (1.0MB)\n",
            "\u001b[K     |████████████████████████████████| 1.0MB 3.4MB/s \n",
            "\u001b[?25hInstalling collected packages: sentencepiece\n",
            "Successfully installed sentencepiece-0.1.85\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xdGdue1Uot15",
        "colab_type": "code",
        "outputId": "2a78d2ac-72e9-4fb0-d440-1e72f093d0db",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        }
      },
      "source": [
        "from google.colab import drive \n",
        "drive.mount('/content/drive')\n",
        "%cd /content/drive/'My Drive'/\n",
        "!pwd"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n",
            "/content/drive/My Drive\n",
            "/content/drive/My Drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TECYs00_4JKl",
        "colab_type": "code",
        "outputId": "a3a6eff2-d429-4a9b-a066-106fffe755f3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from __future__ import absolute_import\n",
        "from __future__ import division\n",
        "from __future__ import print_function\n",
        "from __future__ import unicode_literals\n",
        "\n",
        "import torch\n",
        "from torch.jit import script, trace\n",
        "import torch.nn as nn\n",
        "from torch import optim\n",
        "import torch.nn.functional as F\n",
        "import sentencepiece as spm\n",
        "import csv\n",
        "import random\n",
        "import re\n",
        "import os\n",
        "import codecs\n",
        "from io import open\n",
        "import itertools\n",
        "import pickle\n",
        "import math\n",
        "import sys\n",
        "import datetime\n",
        "import pytz\n",
        "import shutil\n",
        "\n",
        "corpus_name = 'corpus by 5ch'\n",
        "datafile = os.getcwd() + \"/bot/5ch_corpus.txt\"\n",
        "modelPath = os.getcwd() + \"/bot/wiki-ja.model\"\n",
        "\n",
        "# if possible, use GPU. GPUを使用できる場合は使用\n",
        "USE_CUDA = torch.cuda.is_available()\n",
        "print(USE_CUDA)\n",
        "device = torch.device(\"cuda\" if USE_CUDA else \"cpu\")\n",
        "\n",
        "# load a model for sentencepiece. sentencepieceのモデルをロード\n",
        "sp = spm.SentencePieceProcessor()\n",
        "sp.Load(modelPath)\n",
        "\n",
        "JST = pytz.timezone('Asia/Tokyo')\n",
        "program_start = datetime.datetime.now(JST)\n",
        "\n",
        "sys.setrecursionlimit(10000)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "False\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UEAKrEEf4JKw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Default word tokens \n",
        "PAD_token = 0  # Used for padding short sentences　パディング用\n",
        "SOS_token = 1  # Start-of-sentence token　文章の開始位置\n",
        "EOS_token = 2  # End-of-sentence token 文章の終わり\n",
        "\n",
        "class Voc:\n",
        "    def __init__(self, name):\n",
        "        self.name = name\n",
        "        self.trimmed = False\n",
        "        self.word2index = {}\n",
        "        self.word2count = {}\n",
        "        self.index2word = {PAD_token: \"PAD\", SOS_token: \"SOS\", EOS_token: \"EOS\"}\n",
        "        self.num_words = 3  # Count SOS, EOS, PAD\n",
        "\n",
        "    def addSentence(self, sentence):\n",
        "        for word in sp.EncodeAsPieces(sentence):\n",
        "            self.addWord(word)\n",
        "\n",
        "    def addWord(self, word):\n",
        "        if word not in self.word2index:\n",
        "            self.word2index[word] = self.num_words\n",
        "            self.word2count[word] = 1\n",
        "            self.index2word[self.num_words] = word\n",
        "            self.num_words += 1\n",
        "        else:\n",
        "            self.word2count[word] += 1\n",
        "\n",
        "    # Remove words below a certain count threshold. 最低出現数に満たない単語をトリム\n",
        "    def trim(self, min_count):\n",
        "        if self.trimmed:\n",
        "            return\n",
        "        self.trimmed = True\n",
        "\n",
        "        keep_words = []\n",
        "\n",
        "        for k, v in self.word2count.items():\n",
        "            if v >= min_count:\n",
        "                keep_words.append(k)\n",
        "\n",
        "        print('keep_words {} / {} = {:.4f}'.format(\n",
        "            len(keep_words), len(self.word2index), len(keep_words) / len(self.word2index)\n",
        "        ))\n",
        "\n",
        "        # Reinitialize dictionaries. 辞書を初期化\n",
        "        self.word2index = {}\n",
        "        self.word2count = {}\n",
        "        self.index2word = {PAD_token: \"PAD\", SOS_token: \"SOS\", EOS_token: \"EOS\"}\n",
        "        self.num_words = 3 # Count default tokens\n",
        "\n",
        "        for word in keep_words:\n",
        "            self.addWord(word)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c-hW8Ynk4JKy",
        "colab_type": "code",
        "outputId": "e905af22-d5f0-41ca-c348-a92a03cbd7c4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 377
        }
      },
      "source": [
        "MAX_LENGTH = 51  # Maximum sentence length to consider. 文章の最大長さ\n",
        "MIN_LENGTH = 1\n",
        "\n",
        "# Read query/response pairs and return a voc object 質問と応答のペアを読み込みvocオブジェクトを返す\n",
        "def readVocs(datafile, corpus_name):\n",
        "    print(\"Reading lines...\")\n",
        "    # Read the file and split into lines\n",
        "    lines = open(datafile, encoding='utf-8').read().strip().split('\\n')\n",
        "    # Split every line into pairs and normalize\n",
        "    pairs = [[s for s in l.split('\\t')] for l in lines]\n",
        "    voc = Voc(corpus_name)\n",
        "    return voc, pairs\n",
        "\n",
        "# Returns True if both sentences in a pair 'p' are under the MAX_LENGTH threshold\n",
        "# MAX_LENGTH以上またはMIN_LENGTH以下の長さの文章をトリム\n",
        "\n",
        "def filterPair(p):\n",
        "    # Input sequences need to preserve the last word for EOS token\n",
        "    try:\n",
        "        sentence_for_encode = sp.EncodeAsPieces(p[0])\n",
        "        sentence_for_decode = sp.EncodeAsPieces(p[1])\n",
        "        sentence_length_for_Encode = len(sentence_for_encode)\n",
        "        sentence_length_for_Decode = len(sentence_for_decode)\n",
        "    except IndexError:          \n",
        "        sentence_length_for_Encode = 0\n",
        "        sentence_length_for_Decode = 0\n",
        "\n",
        "    return MIN_LENGTH < sentence_length_for_Encode\\\n",
        "    and sentence_length_for_Encode < MAX_LENGTH\\\n",
        "    and MIN_LENGTH < sentence_length_for_Decode\\\n",
        "    and sentence_length_for_Decode < MAX_LENGTH\n",
        "\n",
        "# Filter pairs using filterPair condition /　filterpairを使ってフィルタリング\n",
        "def filterPairs(pairs):\n",
        "    return [pair for pair in pairs if filterPair(pair)]\n",
        "\n",
        "# Using the functions defined above, return a populated voc object and pairs list\n",
        "# 上で定義した関数を使用してvocオブジェクトと会話ペアのリストを返す\n",
        "def loadPrepareData(corpus_name, datafile, save_dir):\n",
        "    print('Start: ' + str(datetime.datetime.now(JST)))\n",
        "    print(\"Start preparing training data ...\")\n",
        "    voc, pairs = readVocs(datafile, corpus_name)\n",
        "    print(\"Read {!s} sentence pairs\".format(len(pairs)))\n",
        "    print('Done!: '  + str(datetime.datetime.now(JST)))\n",
        "    pairs = filterPairs(pairs)\n",
        "    print(\"Trimmed to {!s} sentence pairs\".format(len(pairs)))\n",
        "    print(\"Counting words...\")\n",
        "    for pair in pairs:\n",
        "        voc.addSentence(pair[0])\n",
        "        voc.addSentence(pair[1])\n",
        "    print(\"Counted words:\", voc.num_words)\n",
        "    \n",
        "    return voc, pairs\n",
        "\n",
        "\n",
        "# Load/Assemble voc and pairs vocと会話ペアをロード\n",
        "save_dir = os.path.join(\"data\", \"save\")\n",
        "voc, pairs = loadPrepareData(corpus_name, datafile, save_dir)\n",
        "# Print some pairs to validate　検証用に10ペア出力\n",
        "print(\"\\npairs:\")\n",
        "for pair in pairs[:10]:\n",
        "    print(pair)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Start: 2020-03-12 09:48:24.116399+09:00\n",
            "Start preparing training data ...\n",
            "Reading lines...\n",
            "Read 972336 sentence pairs\n",
            "Done!: 2020-03-12 09:48:28.505392+09:00\n",
            "Trimmed to 968526 sentence pairs\n",
            "Counting words...\n",
            "Counted words: 37614\n",
            "\n",
            "pairs:\n",
            "['popメロンソーダすこ', 'わかるサイズが不満やが飲み切るならあれぐらいがちょうどいい説もある ']\n",
            "['わかるサイズが不満やが飲み切るならあれぐらいがちょうどいい説もある', '自販機専売ってのもレア感あっていい ']\n",
            "['関東で安くキリンガラナをかえる場所教えてくれ', '北海道のアンテナショップ ']\n",
            "['お絵かき壊れたかも\\u3000もう一度トライしてみて', '朝からずっとや ']\n",
            "['朝はお絵かき機能投下失敗したらついでに以後普通のレスもしばらく禁止にされてたわ', '何度も投稿しようとするとそうなるらしい ']\n",
            "['まだまだ12勝3敗ペースや', '15敗ペースなんですがそれは ']\n",
            "['ファイナルラストチャンス稀勢の里', '鵜久森ですら終わったのにまだ粘るのか… ']\n",
            "['フキダシ付けて1コマネタ作れそう', '稀勢の里ワンアウトってとこか ']\n",
            "['鵜久森ですら終わったのにまだ粘るのか…', 'まださいてょが残ってるぞ ']\n",
            "['場所またいで8連敗で横綱の新記録作ったってマ ガチレジェンドやん', '割とガチなアンタッチャブルレコード ']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "acEXjXIr4JK1",
        "colab_type": "code",
        "outputId": "232ccf17-d95f-4727-dc7e-5e64db62b3b1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "MIN_COUNT = 2    # Minimum word count threshold for trimming　最低出現数\n",
        "\n",
        "def trimRareWords(voc, pairs, MIN_COUNT):\n",
        "    # Trim words used under the MIN_COUNT from the voc. 最低出現数未満の単語をカット\n",
        "    voc.trim(MIN_COUNT)\n",
        "    # Filter out pairs with trimmed words. トリムされた単語を含むペアを除外\n",
        "    keep_pairs = []\n",
        "    for pair in pairs:\n",
        "        input_sentence = pair[0]\n",
        "        output_sentence = pair[1]\n",
        "        keep_input = True\n",
        "        keep_output = True\n",
        "        # Check input sentence　入力をチェック\n",
        "        for word in sp.EncodeAsPieces(input_sentence):\n",
        "            if word not in voc.word2index:\n",
        "                keep_input = False\n",
        "                break\n",
        "        # Check output sentence 出力文をチェック\n",
        "        for word in sp.EncodeAsPieces(output_sentence):\n",
        "            if word not in voc.word2index:\n",
        "                keep_output = False\n",
        "                break\n",
        "\n",
        "        # Only keep pairs that do not contain trimmed word(s) in their input or output sentence\n",
        "        # 入力と出力にトリムされた単語を含まないものだけをリスト行き\n",
        "        if keep_input and keep_output:\n",
        "            keep_pairs.append(pair)\n",
        "\n",
        "    print(\"Trimmed from {} pairs to {}, {:.4f} of total\".format(len(pairs), len(keep_pairs), len(keep_pairs) / len(pairs)))\n",
        "    return keep_pairs\n",
        "\n",
        "\n",
        "# Trim voc and pairs　トリム\n",
        "pairs = trimRareWords(voc, pairs, MIN_COUNT)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "keep_words 31403 / 37611 = 0.8349\n",
            "Trimmed from 968526 pairs to 963033, 0.9943 of total\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BRXyc7ES4JK3",
        "colab_type": "code",
        "outputId": "de3cd9a2-e0a9-4269-c780-87cf42391312",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# divide and replace sentence to indexes. 文を分割してインデックスに変更\n",
        "def indexesFromSentence(voc, sentence):\n",
        "    return [voc.word2index[word] for word in sp.EncodeAsPieces(sentence)] + [EOS_token]\n",
        "\n",
        "# zero padding. ゼロ埋めして長さをそろえる\n",
        "def zeroPadding(l, fillvalue=PAD_token):\n",
        "    return list(itertools.zip_longest(*l, fillvalue=fillvalue))\n",
        "\n",
        "def binaryMatrix(l, value=PAD_token):\n",
        "    m = []\n",
        "    for i, seq in enumerate(l):\n",
        "        m.append([])\n",
        "        for token in seq:\n",
        "            if token == PAD_token:\n",
        "                m[i].append(0)\n",
        "            else:\n",
        "                m[i].append(1)\n",
        "    return m\n",
        "\n",
        "# Returns padded input sequence tensor and lengths. 入力された文のテンソルと長さを返す\n",
        "def inputVar(l, voc):\n",
        "    indexes_batch = [indexesFromSentence(voc, sentence) for sentence in l]\n",
        "    lengths = torch.tensor([len(indexes) for indexes in indexes_batch])\n",
        "    padList = zeroPadding(indexes_batch)\n",
        "    padVar = torch.LongTensor(padList)\n",
        "    return padVar, lengths\n",
        "\n",
        "# Returns padded target sequence tensor, padding mask, and max target length 出力文のテンソルと長さを返す\n",
        "def outputVar(l, voc):\n",
        "    indexes_batch = [indexesFromSentence(voc, sentence) for sentence in l]\n",
        "    max_target_len = max([len(indexes) for indexes in indexes_batch])\n",
        "    padList = zeroPadding(indexes_batch)\n",
        "    mask = binaryMatrix(padList)\n",
        "    mask = torch.BoolTensor(mask)\n",
        "    padVar = torch.LongTensor(padList)\n",
        "    return padVar, mask, max_target_len\n",
        "\n",
        "# Returns all items for a given batch of pairs. 与えられたバッチについてすべての要素を返す\n",
        "def batch2TrainData(voc, pair_batch):\n",
        "    pair_batch.sort(key=lambda x: len(sp.EncodeAsPieces(x[0])), reverse=True)\n",
        "    input_batch, output_batch = [], []\n",
        "    for pair in pair_batch:\n",
        "        input_batch.append(pair[0])\n",
        "        output_batch.append(pair[1])\n",
        "    inp, lengths = inputVar(input_batch, voc)\n",
        "    output, mask, max_target_len = outputVar(output_batch, voc)\n",
        "    return inp, lengths, output, mask, max_target_len\n",
        "\n",
        "# Example for validation. 検証\n",
        "small_batch_size = 5\n",
        "batches = batch2TrainData(voc, [random.choice(pairs) for _ in range(small_batch_size)])\n",
        "input_variable, lengths, target_variable, mask, max_target_len = batches\n",
        "\n",
        "print(\"input_variable:\", input_variable)\n",
        "print(\"lengths:\", lengths)\n",
        "print(\"target_variable:\", target_variable)\n",
        "print(\"mask:\", mask)\n",
        "print(\"max_target_len:\", max_target_len)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "input_variable: tensor([[ 3058,     3,     3,     3,     3],\n",
            "        [ 1456,  4914,   513,  4076, 12751],\n",
            "        [ 2390,    34,  6031,   751,  5999],\n",
            "        [  216,  2648,   618,   267,  1769],\n",
            "        [  212,   460,   453,    14,   212],\n",
            "        [    3,    29,   618,   136,    41],\n",
            "        [   14,  1889,  3659,   184,     2],\n",
            "        [  896,   124,    82,    14,     0],\n",
            "        [  872,     3,   120,  3145,     0],\n",
            "        [ 3316,   368,    59,    91,     0],\n",
            "        [  835,   121,   989,     2,     0],\n",
            "        [   28,   121,  1290,     0,     0],\n",
            "        [  810,  6848,   136,     0,     0],\n",
            "        [ 1442,  1753,    14,     0,     0],\n",
            "        [  136,   108,   124,     0,     0],\n",
            "        [   14,    28,     2,     0,     0],\n",
            "        [  188,   648,     0,     0,     0],\n",
            "        [   41,     2,     0,     0,     0],\n",
            "        [    2,     0,     0,     0,     0]])\n",
            "lengths: tensor([19, 18, 16, 11,  7])\n",
            "target_variable: tensor([[ 2144,     3,  1200,     3,   663],\n",
            "        [   19, 16143,  1018,    84,  1882],\n",
            "        [   28,  5945, 12726,  1161,    61],\n",
            "        [ 2628,    68,   167,  2247,  1636],\n",
            "        [   12,   359,   609,   306,   158],\n",
            "        [ 2241,   231,   674,    59,    62],\n",
            "        [   68,   117,  7077,   107,   445],\n",
            "        [12160,     2,  2191,     2,   558],\n",
            "        [   34,     0,     2,     0,   264],\n",
            "        [    3,     0,     0,     0,     2],\n",
            "        [17003,     0,     0,     0,     0],\n",
            "        [ 3375,     0,     0,     0,     0],\n",
            "        [   19,     0,     0,     0,     0],\n",
            "        [   28,     0,     0,     0,     0],\n",
            "        [ 2408,     0,     0,     0,     0],\n",
            "        [   62,     0,     0,     0,     0],\n",
            "        [  335,     0,     0,     0,     0],\n",
            "        [  194,     0,     0,     0,     0],\n",
            "        [    2,     0,     0,     0,     0]])\n",
            "mask: tensor([[ True,  True,  True,  True,  True],\n",
            "        [ True,  True,  True,  True,  True],\n",
            "        [ True,  True,  True,  True,  True],\n",
            "        [ True,  True,  True,  True,  True],\n",
            "        [ True,  True,  True,  True,  True],\n",
            "        [ True,  True,  True,  True,  True],\n",
            "        [ True,  True,  True,  True,  True],\n",
            "        [ True,  True,  True,  True,  True],\n",
            "        [ True, False,  True, False,  True],\n",
            "        [ True, False, False, False,  True],\n",
            "        [ True, False, False, False, False],\n",
            "        [ True, False, False, False, False],\n",
            "        [ True, False, False, False, False],\n",
            "        [ True, False, False, False, False],\n",
            "        [ True, False, False, False, False],\n",
            "        [ True, False, False, False, False],\n",
            "        [ True, False, False, False, False],\n",
            "        [ True, False, False, False, False],\n",
            "        [ True, False, False, False, False]])\n",
            "max_target_len: 19\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7EPoSdwj4JK5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Encoder エンコーダ\n",
        "\n",
        "# import torch.nn as nn\n",
        "\n",
        "class EncoderRNN(nn.Module):\n",
        "    def __init__(self, hidden_size, embedding, n_layers=2, dropout=0):\n",
        "        super(EncoderRNN, self).__init__()\n",
        "        self.n_layers = n_layers\n",
        "        self.hidden_size = hidden_size\n",
        "        self.embedding = embedding\n",
        "\n",
        "        # Initialize GRU; the input_size and hidden_size params are both set to 'hidden_size'\n",
        "        #   because our input size is a word embedding with number of features == hidden_size\n",
        "        # とりあえず入力と出力を隠れ層の値とする(入力と出力の値は変化するものだから)\n",
        "        self.gru = nn.GRU(hidden_size, hidden_size, n_layers,\n",
        "                          dropout=(0 if n_layers == 1 else dropout), bidirectional=True)\n",
        "\n",
        "    def forward(self, input_seq, input_lengths, hidden=None):\n",
        "        # Convert word indexes to embeddings. インデックスをベクトルに変換\n",
        "        embedded = self.embedding(input_seq)\n",
        "        # Pack padded batch of sequences for RNN module. 長さをそろえる\n",
        "        packed = torch.nn.utils.rnn.pack_padded_sequence(embedded, input_lengths, enforce_sorted=False)\n",
        "        # Forward pass through GRU. GRUにかける\n",
        "        outputs, hidden = self.gru(packed, hidden)\n",
        "        # Unpack padding. PackedSequenceオブジェクトに格納\n",
        "        outputs, _ = torch.nn.utils.rnn.pad_packed_sequence(outputs)\n",
        "        # Sum bidirectional GRU outputs. 双方向GRUの出力をまとめる\n",
        "        outputs = outputs[:, :, :self.hidden_size] + outputs[:, : ,self.hidden_size:]\n",
        "        # Return output and final hidden state. 最終的な出力と隠れ状態を返す\n",
        "        return outputs, hidden"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HVrI61Zi4JK7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Luong attention layer\n",
        "\n",
        "class Attn(torch.nn.Module):\n",
        "    def __init__(self, method, hidden_size):\n",
        "        super(Attn, self).__init__()\n",
        "        self.method = method\n",
        "        if self.method not in ['dot', 'general', 'concat']:\n",
        "            raise ValueError(self.method, \"is not an appropriate attention method.\")\n",
        "        self.hidden_size = hidden_size\n",
        "        if self.method == 'general':\n",
        "            self.attn = torch.nn.Linear(self.hidden_size, hidden_size)\n",
        "        elif self.method == 'concat':\n",
        "            self.attn = torch.nn.Linear(self.hidden_size * 2, hidden_size)\n",
        "            self.v = torch.nn.Parameter(torch.FloatTensor(hidden_size))\n",
        "\n",
        "    def dot_score(self, hidden, encoder_output):\n",
        "        return torch.sum(hidden * encoder_output, dim=2)\n",
        "\n",
        "    def general_score(self, hidden, encoder_output):\n",
        "        energy = self.attn(encoder_output)\n",
        "        return torch.sum(hidden * energy, dim=2)\n",
        "\n",
        "    def concat_score(self, hidden, encoder_output):\n",
        "        energy = self.attn(torch.cat((hidden.expand(encoder_output.size(0), -1, -1), encoder_output), 2)).tanh()\n",
        "        return torch.sum(self.v * energy, dim=2)\n",
        "\n",
        "    def forward(self, hidden, encoder_outputs):\n",
        "        # Calculate the attention weights (energies) based on the given method\n",
        "        # attentionの重みをメソッドに応じて計算\n",
        "        if self.method == 'general':\n",
        "            attn_energies = self.general_score(hidden, encoder_outputs)\n",
        "        elif self.method == 'concat':\n",
        "            attn_energies = self.concat_score(hidden, encoder_outputs)\n",
        "        elif self.method == 'dot':\n",
        "            attn_energies = self.dot_score(hidden, encoder_outputs)\n",
        "\n",
        "        # Transpose max_length and batch_size dimensions\n",
        "        # 最大長さとバッチサイズの次元を入れ替える\n",
        "        attn_energies = attn_energies.t()\n",
        "\n",
        "        # Return the softmax normalized probability scores (with added dimension)\n",
        "        # ソフトマックス　正規化して返す\n",
        "        return F.softmax(attn_energies, dim=1).unsqueeze(1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A0Zwz1iy4JK-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class LuongAttnDecoderRNN(nn.Module):\n",
        "    def __init__(self, attn_model, embedding, hidden_size, output_size, n_layers=2, dropout=0.1):\n",
        "        super(LuongAttnDecoderRNN, self).__init__()\n",
        "\n",
        "        # Keep for reference\n",
        "        self.attn_model = attn_model\n",
        "        self.hidden_size = hidden_size\n",
        "        self.output_size = output_size\n",
        "        self.n_layers = n_layers\n",
        "        self.dropout = dropout\n",
        "\n",
        "        # Define layers\n",
        "        self.embedding = embedding\n",
        "        self.embedding_dropout = nn.Dropout(dropout)\n",
        "        self.gru = nn.GRU(hidden_size, hidden_size, n_layers, dropout=(0 if n_layers == 1 else dropout))\n",
        "        self.concat = nn.Linear(hidden_size * 2, hidden_size)\n",
        "        self.out = nn.Linear(hidden_size, output_size)\n",
        "\n",
        "        self.attn = Attn(attn_model, hidden_size)\n",
        "\n",
        "    def forward(self, input_step, last_hidden, encoder_outputs):\n",
        "        # Note: we run this one step (word) at a time \n",
        "        # Get embedding of current input word 入力単語のembedding\n",
        "        embedded = self.embedding(input_step)\n",
        "        embedded = self.embedding_dropout(embedded)\n",
        "        # Forward through unidirectional GRU　一方向のGRUにかける\n",
        "        rnn_output, hidden = self.gru(embedded, last_hidden)\n",
        "        # Calculate attention weights from the current GRU output　現在のGRUからの出力の重みを計算\n",
        "        attn_weights = self.attn(rnn_output, encoder_outputs)\n",
        "        # Multiply attention weights to encoder outputs to get new \"weighted sum\" context vector\n",
        "        # attentionの重みをencoderのアウトプットに掛けて、合計の重みを得る\n",
        "        context = attn_weights.bmm(encoder_outputs.transpose(0, 1))\n",
        "        # Concatenate weighted context vector and GRU output using Luong eq. 5\n",
        "        # 重みとGRUの出力を結合\n",
        "        rnn_output = rnn_output.squeeze(0)\n",
        "        context = context.squeeze(1)\n",
        "        concat_input = torch.cat((rnn_output, context), 1)\n",
        "        concat_output = torch.tanh(self.concat(concat_input))\n",
        "        # Predict next word using Luong eq. 6 次の単語を推論\n",
        "        output = self.out(concat_output)\n",
        "        output = F.softmax(output, dim=1)\n",
        "        # Return output and final hidden state 出力と最終的な隠れ状態を出力\n",
        "        return output, hidden"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L_RWo2da4JLA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def maskNLLLoss(inp, target, mask):\n",
        "    nTotal = mask.sum()\n",
        "    crossEntropy = -torch.log(torch.gather(inp, 1, target.view(-1, 1)))\n",
        "    loss = crossEntropy.masked_select(mask).mean()\n",
        "    loss = loss.to(device)\n",
        "    return loss, nTotal.item()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ul0yP4ve4JLC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(input_variable, lengths, target_variable, mask, max_target_len, encoder, decoder, embedding,\n",
        "          encoder_optimizer, decoder_optimizer, batch_size, clip, max_length=MAX_LENGTH):\n",
        "\n",
        "    # Zero gradients 境界\n",
        "    encoder_optimizer.zero_grad()\n",
        "    decoder_optimizer.zero_grad()\n",
        "\n",
        "    # Set device options 環境の設定\n",
        "    input_variable = input_variable.to(device)\n",
        "    lengths = lengths.to(device)\n",
        "    target_variable = target_variable.to(device)\n",
        "    mask = mask.to(device)\n",
        "\n",
        "    # Initialize variables 変数の初期化\n",
        "    loss = 0\n",
        "    print_losses = []\n",
        "    n_totals = 0\n",
        "\n",
        "    # Forward pass through encoder encoderにかける\n",
        "    encoder_outputs, encoder_hidden = encoder(input_variable, lengths)\n",
        "\n",
        "    # Create initial decoder input (start with SOS tokens for each sentence)\n",
        "    # SOSから最初のdecoder入力を生成\n",
        "    decoder_input = torch.LongTensor([[SOS_token for _ in range(batch_size)]])\n",
        "    decoder_input = decoder_input.to(device)\n",
        "\n",
        "    # Set initial decoder hidden state to the encoder's final hidden state\n",
        "    # 最初のdecoderの隠れ状態をencoderの最終的な隠れ状態\n",
        "    decoder_hidden = encoder_hidden[:decoder.n_layers]\n",
        "\n",
        "    # Determine if we are using teacher forcing this iteration　/ teacher forcingを使用するか判断\n",
        "    use_teacher_forcing = True if random.random() < teacher_forcing_ratio else False\n",
        "\n",
        "    # Forward batch of sequences through decoder one time step at a time\n",
        "    # シーケンスのバッチをdecoderにかける\n",
        "    if use_teacher_forcing:\n",
        "        for t in range(max_target_len):\n",
        "            decoder_output, decoder_hidden = decoder(\n",
        "                decoder_input, decoder_hidden, encoder_outputs\n",
        "            )\n",
        "            # Teacher forcing: next input is current target　次の入力を現在のターゲット\n",
        "            decoder_input = target_variable[t].view(1, -1)\n",
        "            # Calculate and accumulate loss　損失を計算して合計\n",
        "            mask_loss, nTotal = maskNLLLoss(decoder_output, target_variable[t], mask[t])\n",
        "            loss += mask_loss\n",
        "            print_losses.append(mask_loss.item() * nTotal)\n",
        "            n_totals += nTotal\n",
        "    else:\n",
        "        for t in range(max_target_len):\n",
        "            decoder_output, decoder_hidden = decoder(\n",
        "                decoder_input, decoder_hidden, encoder_outputs\n",
        "            )\n",
        "            # No teacher forcing: next input is decoder's own current output　次の入力はdecoderの出力\n",
        "            _, topi = decoder_output.topk(1)\n",
        "            decoder_input = torch.LongTensor([[topi[i][0] for i in range(batch_size)]])\n",
        "            decoder_input = decoder_input.to(device)\n",
        "            # Calculate and accumulate loss　損失を計算して合計\n",
        "            mask_loss, nTotal = maskNLLLoss(decoder_output, target_variable[t], mask[t])\n",
        "            loss += mask_loss\n",
        "            print_losses.append(mask_loss.item() * nTotal)\n",
        "            n_totals += nTotal\n",
        "\n",
        "    # Perform backpropatation　逆勾配\n",
        "    loss.backward()\n",
        "\n",
        "    # Clip gradients: gradients are modified in place　勾配を適切な位置に修正\n",
        "    _ = torch.nn.utils.clip_grad_norm_(encoder.parameters(), clip)\n",
        "    _ = torch.nn.utils.clip_grad_norm_(decoder.parameters(), clip)\n",
        "\n",
        "    # Adjust model weights モデルの重みを調節\n",
        "    encoder_optimizer.step()\n",
        "    decoder_optimizer.step()\n",
        "\n",
        "    return sum(print_losses) / n_totals"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LYPjs6BB4JLE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def trainIters(model_name, voc, pairs, encoder, decoder, encoder_optimizer, decoder_optimizer, embedding, encoder_n_layers, decoder_n_layers, save_dir, n_iteration, batch_size, print_every, save_every, clip, corpus_name, loadFilename):\n",
        "\n",
        "    # Load batches for each iteration バッチとイテレーションをロード\n",
        "    training_batches = [batch2TrainData(voc, [random.choice(pairs) for _ in range(batch_size)])\n",
        "                      for _ in range(n_iteration)]\n",
        "\n",
        "    # Initializations　初期化\n",
        "    print('Initializing ...')\n",
        "    start_iteration = 1\n",
        "    start_epoch = 1\n",
        "    print_loss = 0\n",
        "    if loadFilename:\n",
        "        start_iteration = checkpoint['iteration'] + 1\n",
        "        start_epoch = checkpoint['epochs']\n",
        "\n",
        "    # Training loop　訓練\n",
        "    print(\"Training...\")\n",
        "    print(program_start)\n",
        "    for e in range(start_epoch, epochs + 1):\n",
        "      \n",
        "      if e != start_epoch:\n",
        "        start_iteration = 1  \n",
        "\n",
        "      # Epochs 学習の周回数\n",
        "      for iteration in range(start_iteration, n_iteration + 1):\n",
        "          training_batch = training_batches[iteration - 1]\n",
        "          # Extract fields from batch バッチからフィールドを抽出\n",
        "          input_variable, lengths, target_variable, mask, max_target_len = training_batch\n",
        "\n",
        "          # Run a training iteration with batch　　訓練実行処理\n",
        "          loss = train(input_variable, lengths, target_variable, mask, max_target_len, encoder,\n",
        "                      decoder, embedding, encoder_optimizer, decoder_optimizer, batch_size, clip, e)\n",
        "          print_loss += loss\n",
        "\n",
        "          # Print progress　進捗の出力\n",
        "          if iteration % print_every == 0:\n",
        "              print_loss_avg = print_loss / print_every\n",
        "              print(\"Epoch: {}; Iteration: {}; Percent complete: {:.1f}%; Average loss: {:.4f}\".format(\n",
        "                  e, iteration, (iteration + ((e - 1) * 15000)) / (n_iteration * epochs * 100), print_loss_avg\n",
        "                  ))\n",
        "              print(str(datetime.datetime.now(JST) - program_start))\n",
        "              print_loss = 0\n",
        "\n",
        "          # Save checkpoint　保存\n",
        "          if (iteration % save_every == 0):\n",
        "              directory = os.path.join(model_name)\n",
        "              if not os.path.exists(directory):\n",
        "                  os.makedirs(directory)\n",
        "\n",
        "              else:\n",
        "                shutil.rmtree(directory)\n",
        "                os.makedirs(directory)\n",
        "\n",
        "              torch.save({\n",
        "                  'epochs': e,\n",
        "                  'iteration': iteration,\n",
        "                  'en': encoder.state_dict(),\n",
        "                  'de': decoder.state_dict(),\n",
        "                  'en_opt': encoder_optimizer.state_dict(),\n",
        "                  'de_opt': decoder_optimizer.state_dict(),\n",
        "                  'loss': loss,\n",
        "                  'voc_dict': voc.__dict__,\n",
        "                  'embedding': embedding.state_dict()\n",
        "              }, os.path.join(directory, '{}-{}{}({:.2f}).tar'.format(e, iteration, 'checkpoint', print_loss_avg)))\n",
        "\n",
        "              print('saved')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T35F17Tt4JLH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class GreedySearchDecoder(nn.Module):\n",
        "    def __init__(self, encoder, decoder):\n",
        "        super(GreedySearchDecoder, self).__init__()\n",
        "        self.encoder = encoder\n",
        "        self.decoder = decoder\n",
        "\n",
        "    def forward(self, input_seq, input_length, max_length):\n",
        "        # Forward input through encoder model / encoderモデルにかける入力\n",
        "        encoder_outputs, encoder_hidden = self.encoder(input_seq, input_length)\n",
        "        # Prepare encoder's final hidden layer to be first hidden input to the decoder\n",
        "        # encoderの最終的な隠れ層をdecoderの最初の隠れ入力にする\n",
        "        decoder_hidden = encoder_hidden[:decoder.n_layers]\n",
        "        # Initialize decoder input with SOS_token　/ decoderの入力を初期化\n",
        "        decoder_input = torch.ones(1, 1, device=device, dtype=torch.long) * SOS_token\n",
        "        # Initialize tensors to append decoded words to テンソルを初期化してdecoderの単語を追加\n",
        "        all_tokens = torch.zeros([0], device=device, dtype=torch.long)\n",
        "        all_scores = torch.zeros([0], device=device)\n",
        "        # Iteratively decode one word token at a time　繰り返しdecode\n",
        "        for _ in range(max_length):\n",
        "            # Forward pass through decoder / decoderにかける\n",
        "            decoder_output, decoder_hidden = self.decoder(decoder_input, decoder_hidden, encoder_outputs)\n",
        "            # Obtain most likely word token and its softmax score 最も適切な単語とsoftmaxのスコアを取得\n",
        "            decoder_scores, decoder_input = torch.max(decoder_output, dim=1)\n",
        "            # Record token and score トークンとスコアを記録\n",
        "            all_tokens = torch.cat((all_tokens, decoder_input), dim=0)\n",
        "            all_scores = torch.cat((all_scores, decoder_scores), dim=0)\n",
        "            # Prepare current token to be next decoder input (add a dimension)\n",
        "            #　現在のトークンと次のdecoderの入力を取得\n",
        "            decoder_input = torch.unsqueeze(decoder_input, 0)\n",
        "        # Return collections of word tokens and scores　単語のトークンとスコアのコレクションを返す\n",
        "        return all_tokens, all_scores"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ftp5ET1x4JLL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def evaluate(encoder, decoder, searcher, voc, sentence, max_length=MAX_LENGTH):\n",
        "    ### Format input sentence as a batch\n",
        "    # words -> indexes　単語をインデックスに\n",
        "    indexes_batch = [indexesFromSentence(voc, sentence)]\n",
        "    # Create lengths tensor テンソルの長さを生成\n",
        "    lengths = torch.tensor([len(indexes) for indexes in indexes_batch])\n",
        "    # Transpose dimensions of batch to match models' expectations　モデルの推論を合わせるためにバッチの次元を入れ替える\n",
        "    input_batch = torch.LongTensor(indexes_batch).transpose(0, 1)\n",
        "    # Use appropriate device　適切なデバイスを使用\n",
        "    input_batch = input_batch.to(device)\n",
        "    lengths = lengths.to(device)\n",
        "    # Decode sentence with searcher　文章をdecode\n",
        "    tokens, scores = searcher(input_batch, lengths, max_length)\n",
        "    # indexes -> words インデックスを単語に\n",
        "    decoded_words = [voc.index2word[token.item()] for token in tokens]\n",
        "    return decoded_words\n",
        "\n",
        "\n",
        "def evaluateInput(encoder, decoder, searcher, voc):\n",
        "    input_sentence = ''\n",
        "    table = set_NGTable()\n",
        "    regax = re.compile(\n",
        "        '[!\"#$%&\\'\\\\\\\\()*+,-./:;<=>?@[\\\\]^_`{|}~「」〔〕“”〈〉『』【】＆＊・（）＄＃＠。、？！｀＋￥％]'\n",
        "        )\n",
        "    while(1):\n",
        "        try:\n",
        "            # Get input sentence 入力を取得\n",
        "            input_sentence = input('> ')\n",
        "            input_sentence = regax.sub('', input_sentence)\n",
        "            # remove symbol 記号を外す\n",
        "            text = re.sub(\n",
        "                '[!\"#$%&\\'\\\\\\\\()*+,-./:;<=>?@[\\\\]^_`{|}~「」〔〕“”〈〉『』【】＆＊・（）＄＃＠。、？！｀＋￥％�]', '', input_sentence\n",
        "                )        \n",
        "            # remove emoji 絵文字を外す\n",
        "            input_sentence = ''.join(c for c in input_sentence if c not in emoji.UNICODE_EMOJI)            \n",
        "            # Check if it is quit case 会話中止処理\n",
        "            if input_sentence == 'ほな' or input_sentence == 'グッバイ': break\n",
        "            # Evaluate sentence 評価\n",
        "            output_words = evaluate(encoder, decoder, searcher, voc, input_sentence)\n",
        "            # Format and print response sentence 文章整理\n",
        "            output_words[:] = [x for x in output_words if not (x == 'EOS' or x == 'PAD')]\n",
        "            sentence = ''.join(output_words)\n",
        "            s = replace_NGword(sentence, table)\n",
        "            print('Bot: ' + s.replace('▁', ''))\n",
        "\n",
        "        except KeyError:\n",
        "            print(\"難しい言葉使うのやめろ\")\n",
        "# translate F word to more \"soft\" expression 不適切用語を変換\n",
        "def replace_NGword(sentence, table):\n",
        "    result = re.sub('({})'.format(\n",
        "        '|'.join(map(re.escape, table.keys()))),\n",
        "        lambda m: table[m.group()], sentence)\n",
        "\n",
        "    return result\n",
        "\n",
        "# prepare table to replace F words 不適切用語変換用の辞書を用意\n",
        "def set_NGTable():\n",
        "    fword = os.getcwd()+'/bot/fword.csv'\n",
        "    ng = {}\n",
        "    with open(fword, 'r', encoding='utf-8') as fw:\n",
        "        reader = csv.reader(fw)\n",
        "        next(reader)\n",
        "        for row in reader:\n",
        "            ng[row[0]] = row[1]\n",
        "\n",
        "    return ng"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rP_FRXsw4JLN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "08bb6f7e-222f-4447-dd67-7c9f0f933ff2"
      },
      "source": [
        "# Configure models モデル設定\n",
        "model_name = 'cb_model'\n",
        "attn_model = 'dot'\n",
        "#attn_model = 'general'\n",
        "#attn_model = 'concat'\n",
        "hidden_size = 1500\n",
        "encoder_n_layers = 4\n",
        "decoder_n_layers = 4\n",
        "dropout = 0.1\n",
        "batch_size = 64\n",
        "\n",
        "# Set checkpoint to load from; set to None if starting from scratch　チェックポイントの設定\n",
        "loadFilename = '/content/drive/My Drive/11epochs/model.tar'\n",
        "checkpoint_iter = 15000\n",
        "# For copy and paste: '/content/drive/My Drive/cb_model/checkpoint.tar'\n",
        "\n",
        "#loadFilename = os.path.join(save_dir, model_name, corpus_name,\n",
        "#                            '{}-{}_{}'.format(encoder_n_layers, decoder_n_layers, hidden_size),\n",
        "#                            '{}_checkpoint.tar'.format(checkpoint_iter))\n",
        "\n",
        "\n",
        "# Load model if a loadFilename is provided　モデルのロード\n",
        "if loadFilename:\n",
        "    # make space on memory　メモリの確保\n",
        "    torch.cuda.empty_cache()\n",
        "    with open('voc.pickle', 'wb') as v:\n",
        "      pickle.dump(voc, v)\n",
        "    # If loading on same machine the model was trained on　訓練済みモデルのロード\n",
        "    if torch.cuda.is_available():\n",
        "      checkpoint = torch.load(loadFilename)\n",
        "    else:\n",
        "      checkpoint = torch.load(loadFilename,  map_location='cpu')\n",
        "    # If loading a model trained on GPU to CPU\n",
        "    #checkpoint = torch.load(loadFilename, map_location=torch.device('cpu'))\n",
        "    encoder_sd = checkpoint['en']\n",
        "    decoder_sd = checkpoint['de']\n",
        "    encoder_optimizer_sd = checkpoint['en_opt']\n",
        "    decoder_optimizer_sd = checkpoint['de_opt']\n",
        "    embedding_sd = checkpoint['embedding']\n",
        "    voc.__dict__ = checkpoint['voc_dict']\n",
        "\n",
        "print('Building encoder and decoder ...')\n",
        "# Initialize word embeddings\n",
        "embedding = nn.Embedding(voc.num_words, hidden_size)\n",
        "if loadFilename:\n",
        "    embedding.load_state_dict(embedding_sd)\n",
        "# Initialize encoder & decoder models　モデル初期化\n",
        "encoder = EncoderRNN(hidden_size, embedding, encoder_n_layers, dropout)\n",
        "decoder = LuongAttnDecoderRNN(attn_model, embedding, hidden_size, voc.num_words, decoder_n_layers, dropout)\n",
        "if loadFilename:\n",
        "    encoder.load_state_dict(encoder_sd)\n",
        "    decoder.load_state_dict(decoder_sd)\n",
        "# Use appropriate device\n",
        "encoder = encoder.to(device)\n",
        "decoder = decoder.to(device)\n",
        "print('Models built and ready to go!')\n"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Building encoder and decoder ...\n",
            "Models built and ready to go!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2z9o6w0No4Nr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "86a52530-9205-4900-f9fb-34b9cd78a8c8"
      },
      "source": [
        "# if training, uncomment and run this cell\n",
        "# 訓練する場合はコメントを外してセルを実行\n",
        "\n",
        "'''\n",
        "# Configure training/optimization\n",
        "clip = 50.0\n",
        "teacher_forcing_ratio = 1.0\n",
        "learning_rate = 0.0001\n",
        "decoder_learning_ratio = 5.0\n",
        "n_iteration = 15000\n",
        "print_every = 1000\n",
        "save_every = 5000\n",
        "epochs = 15\n",
        "\n",
        "# Ensure dropout layers are in train mode\n",
        "encoder.train()\n",
        "decoder.train()\n",
        "\n",
        "# Initialize optimizers\n",
        "print('Building optimizers ...')\n",
        "encoder_optimizer = optim.Adam(encoder.parameters(), lr=learning_rate)\n",
        "decoder_optimizer = optim.Adam(decoder.parameters(), lr=learning_rate * decoder_learning_ratio)\n",
        "if loadFilename:\n",
        "    encoder_optimizer.load_state_dict(encoder_optimizer_sd)\n",
        "    decoder_optimizer.load_state_dict(decoder_optimizer_sd)\n",
        "\n",
        "# Run training iterations\n",
        "print(\"Starting Training!\")\n",
        "\n",
        "trainIters(model_name, voc, pairs, encoder, decoder, encoder_optimizer, decoder_optimizer,\n",
        "           embedding, encoder_n_layers, decoder_n_layers, save_dir, n_iteration, batch_size,\n",
        "           print_every, save_every, clip, corpus_name, loadFilename)\n",
        "'''"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n# Configure training/optimization\\nclip = 50.0\\nteacher_forcing_ratio = 1.0\\nlearning_rate = 0.0001\\ndecoder_learning_ratio = 5.0\\nn_iteration = 15000\\nprint_every = 1000\\nsave_every = 5000\\nepochs = 15\\n\\n# Ensure dropout layers are in train mode\\nencoder.train()\\ndecoder.train()\\n\\n# Initialize optimizers\\nprint(\\'Building optimizers ...\\')\\nencoder_optimizer = optim.Adam(encoder.parameters(), lr=learning_rate)\\ndecoder_optimizer = optim.Adam(decoder.parameters(), lr=learning_rate * decoder_learning_ratio)\\nif loadFilename:\\n    encoder_optimizer.load_state_dict(encoder_optimizer_sd)\\n    decoder_optimizer.load_state_dict(decoder_optimizer_sd)\\n\\n# Run training iterations\\nprint(\"Starting Training!\")\\n\\ntrainIters(model_name, voc, pairs, encoder, decoder, encoder_optimizer, decoder_optimizer,\\n           embedding, encoder_n_layers, decoder_n_layers, save_dir, n_iteration, batch_size,\\n           print_every, save_every, clip, corpus_name, loadFilename)\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PM6mpvPv9MFL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "5740ed9b-5e6c-4f98-f2ef-2949a35ed056"
      },
      "source": [
        "print('Done!: ' + str(datetime.datetime.now(JST)))"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Done!: 2020-03-12 09:52:05.030324+09:00\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "liXPcnSmXNOx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "outputId": "9c412393-7255-4b13-e216-4bad3cb06c9d"
      },
      "source": [
        "# Set dropout layers to eval mode 評価モード\n",
        "encoder.eval()\n",
        "decoder.eval()\n",
        " \n",
        "# Initialize search module サーチモジュールの初期化\n",
        "searcher = GreedySearchDecoder(encoder, decoder)\n",
        " \n",
        "start_bot = datetime.datetime.now(JST)\n",
        "print(start_bot - program_start)\n",
        "# Begin chatting (uncomment and run the following line to begin) チャット開始\n",
        "evaluateInput(encoder, decoder, searcher, voc)\n"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0:05:37.662215\n",
            "> 何歳？\n",
            "Bot: 40\n",
            "> 学歴は？\n",
            "Bot: 東大や此花や\n",
            "> 年収は？\n",
            "Bot: 450万\n",
            "> 身長は？\n",
            "Bot: 158cm\n",
            "> 体重は？\n",
            "Bot: 40kg\n",
            "> どこ住みや？\n",
            "Bot: 神奈川や\n",
            "> ほな\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}